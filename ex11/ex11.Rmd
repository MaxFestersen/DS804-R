---
title: 'DS804: Exercise 11: Group Project 1: Clustering'
author: Alexander Dernild, Christian R. Andersen, Johannes Sørensen, Mathias P.
  Larsen & Max F. Hansen
date: "28/4/2021"
output: pdf_document
---
```{r Imports, echo = FALSE, message = FALSE}
# Imports ---------------------------------------
library(tidyverse) # For convenience, plots, tables and probably some other stuff.
library(cluster)
library(factoextra)
<<<<<<< HEAD
library(SentimentAnalysis) # for sentiment analysis
=======
library(dbscan)
>>>>>>> e5882edb8fc06cdee04e70e52e3c417640947e68
# Source ----------------------------------------
source("../cluster_quality.R") # Functions for data analysis
```

```{r Seeding, echo = FALSE, message = FALSE}
set.seed(42069) # Set seed to remove randomness when replicating results
```


# **DS804 Assignment 1 - Clustering**
28/04/2021  

## Created by  

* Alexander Ibsen Dernild, alder17  
* Christian Rohde Andersen, chran20  
* Johannes Christian Sørensen, josoe20  
* Mathias Profft Larsen, matla20  
* Max Festersen Hansen, maxfh20  

## 1. Introduction
For this project, we have chosen a dataset in the "Shape sets" at [https://cs.joensuu.fi/sipu/datasets/]. In this report we will explain why we chose this dataset, which methods we have chosen to analyze the data and explain the results of our analysis. At last we will be making a comparison of the methods and see how it can be upscaled to larger datasets.


### 1.1 Zahn's Compound dataset
For this exercise, we needed shape data set. We choose to use the compound
dataset, from C.T. Zahn, **IEEE Transactions on Computers**, 1971.
The compound data was chosen for... reasons.<!-- XX TODO: expand reason.  -->

```{r loading-dataset, echo = FALSE, message = FALSE}
# Data load
compound.df <- read.csv("Compound.txt", sep = "\t", header = F)
# Adding lables
names(compound.df) <- c("x", "y", "class")

compound.df <- compound.df %>% 
  mutate(class = ifelse(class == 1, "Rain", class)) %>% 
  mutate(class = ifelse(class == 2, "Corona-virus", class)) %>% 
  mutate(class = ifelse(class == 3, "Left-eye", class)) %>% 
  mutate(class = ifelse(class == 4, "Right-eye", class)) %>% 
  mutate(class = ifelse(class == 5, "Lips", class)) %>% 
  mutate(class = ifelse(class == 6, "Tounge", class))

compound.df$class <- factor(compound.df$class)
```

```{r plotting-initial-data, warning=FALSE, echo=FALSE}
ggplot(compound.df, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Compound Data") +
  theme_light()
```
Above the data can be seen, colored by class. The clases is named 1-8.
The data had 8 classes, thus 8 colors are used.


```{r normalizing-data, warning=FALSE, echo=FALSE}
norm.compound <- scale(compound.df[1:2]) %>% 
  data.frame()
norm.compound$class <- compound.df$class
td <- norm.compound[1:2] # Test data - the data we test on

ggplot(norm.compound, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Compound Data normalized") +
  theme_light()


fviz_nbclust(norm.compound[1:2], kmeans, method='silhouette') # elbow plot
```
We normalize the data to be closer to zero (centered zero). This is done to normalize the weight and remove bias from large numbers.

## 2 Methods  


### 2.1 Algorithms and implementation  
<!-- XX TODO: explain witch algorithms and implementations that were used -->



## 3 Analysis of the Methods
<!-- XX TODO: find analysis methods -->


### 3.1 k-means
With k-means we expected it would be able to create good clusters
for the eyes and tongue, since they have a clear mean. We would expect it to
have some trouble with the lips, the rain and the virus,
since the cluster-means overlap with other clusters.

```{r k-means-testing-methods, warning=FALSE, echo=FALSE}
set.seed(42069) # Set seed to remove randomness when replicating results
c_macqueen <- kmeans(td, 6, iter.max = 20, algorithm = "MacQueen")
c_forgy <- kmeans(td, 6, iter.max = 20, algorithm = "Forgy")
c_har_won <- kmeans(td, 6)

test <- data.frame(macqueen = c_macqueen$cluster,
                   forgy = c_forgy$cluster,
                   har_won = c_har_won$cluster,
                   class = norm.compound$class)

macqueen <- table(test$macqueen, test$class, dnn = c("MacQueen", "Class"))
forgy <- table(test$forgy, test$class, dnn = c("Forgy", "Class"))
har_won <- table(test$har_won, test$class, dnn = c("Harting-Wong", "Class"))

macqueen
forgy
har_won

cluster_report(macqueen)
cluster_report(forgy)
cluster_report(har_won)

si <- silhouette(c_har_won$cluster, dist(norm.compound))
silhouette_score <- mean(si[,3])
```

```{r k-means-visualization, warning=FALSE, echo=FALSE}
norm.compound$macqueen <- factor(test$macqueen)
norm.compound$forgy <- factor(test$forgy)
norm.compound$har_won <- factor(test$har_won)

plot_stuff <- function(df, predicted, cap) {
  ggplot(df, aes(x, y, shape = class, color = predicted)) +
    geom_point() +
    labs(title = cap) +
    theme_light()
}

plot_stuff(norm.compound, norm.compound$macqueen, "Macqueen")
plot_stuff(norm.compound, norm.compound$forgy, "Forgy")
plot_stuff(norm.compound, norm.compound$har_won, "Hartigan Wong")
```
Using the k-means algorithms: Macqueen, Loyd-Forgy and Hartigan-Wong. We found
Hartigan-Wong was the most accurate when looking at the accuracy of estimates,
and mean macro average. They are visualized above.
Regardless of method, it seems the algorithms are having a hard time distinguishing:
1. Lips & Tongue
2. Left-eye & Right-eye
3. Rain
4. Corona-virus
5. Corona-virus & Rain

It is worth noting that Hartigan-Wong gets Right-eye more wrong with no clustering,
and has a harder time handling Rain and Corona-Virus,
using more clusteres there than the others. It does get Lips and Left-eye right.

It has the best visual result, with the creation og a Mouth, Eyes and multicolored
Scenery.

From what we predicted, we correctly predicted some of the issues with kmeans.
Additionally we were surprised to see Tongue being split in some cases.
The eyes were also never classified correctly, with them being clustered close
together and sometimes together with Lips and Tongue.
<!--XX TODO: Ret fejl i de beskrivelser Max har skrevet ovenfor -->

### 3.2 knn
<!-- Mathias: XX TODO: perform analysis -->


### 3.3 OPTICS
<!-- Alexander: XX TODO: perform analysis -->


```{r}
set.seed(2)
dat <- compound.df[1:2] # data

opt_clust <- optics(dat, minPts = 7)
plot(opt_clust)

plot(dat, col = "grey", main = "Clustering order")
polygon(dat[opt_clust$order,])

res_db <- extractDBSCAN(opt_clust, 1.6)
plot(res_db, sub = paste0("DBSCAN extraction eps = ", res_db$eps_cl))
hullplot(dat, res_db, sub = paste0("DBSCAN extraction eps = ", res_db$eps_cl))

res_xi <- extractXi(opt_clust, xi = 0.058)
plot(res_xi, sub = paste0("Xi extraction steepness threshold = ", res_xi$xi))
hullplot(dat, res_xi, sub = paste0("Xi extraction steepness threshold = ", res_xi$xi))

dat$xi_clust <- as.factor(res_xi$cluster)
dat$db_clust <- as.factor(res_db$cluster)
dat$class <- compound.df$class

db_clust <- table(dat$db_clust, dat$class)
xi_clust <- table(dat$xi_clust, dat$class)

db_clust # 0 is noise points
xi_clust # 0 is noise points

#cluster_report(db_clust) # doesn't work as dbscan method only finds 4 clusters
cluster_report(xi_clust)
```

### 3.4 DBSCAN
<!-- Christian & Johannes: XX TODO: perform analysis -->
```{r}
## Find suitable DBSCAN parameters:
## 1. We use minPts = dim + 1 = 5 for iris. A larger value can also be used.
## 2. We inspect the  k-NN distance plot for k = minPts - 1 = 4
kNNdistplot(td, k = 2 - 1)

## Noise seems to start around a 4-NN distance of .3
abline(h=.2, col = "red", lty=2)

# Fitting DBScan clustering Model 
# to training dataset
Dbscan_cl <- dbscan(td, eps = 0.2, MinPts = 2 + 1)
Dbscan_cl

# Checking cluster
Dbscan_cl$cluster

# Table
table(Dbscan_cl$cluster, compound.df$class)

# Plotting Cluster
plot(Dbscan_cl, td, main = "DBScan")
```
DBscan has two parameters: minPts (Dimensionality + 1, or higher), and epsilon from KKn.


### 3.5 Silutte coefficient
<!-- : XX TODO: perform analysis -->


## 4 Results
<!-- XX TODO: Explain what we found / sum up results -->

### 4.1 Comparison



## 5 More intresing data
<!-- Max: XX TODO: find more intresting data for us and analyze it. -->
```{r name1, warning=FALSE, echo=FALSE}
shrek.1 <- read.csv("dataset/Shrek.csv", sep = ",")[-1]
shrek.2 <- read.csv("dataset/Shrek 2.csv", sep = ",")[-1]
shrek.3 <- read.csv("dataset/Shrek the Third.csv", sep = ",")[-1]
shrek.4 <- read.csv("dataset/Shrek Forever After.csv", sep = ",")[-1]
shreks <- shrek.1 %>%
  full_join(shrek.2) %>% 
  full_join(shrek.3) %>% 
  full_join(shrek.4) %>%
  select(-date) %>% # remove date from dataset
  rename("review" = text) %>% # Rename text to review
  mutate(review.and.title = paste(r_title, review)) %>% 
  mutate(sentiment_title = analyzeSentiment(r_title, removeStopwords = FALSE)[["SentimentGI"]],
         sentiment_reveiw = analyzeSentiment(review, reviewremoveStopwords = TRUE)[["SentimentGI"]],
         sentiment = analyzeSentiment(review.and.title, reviewremoveStopwords = TRUE)[["SentimentGI"]]) %>%
  na.omit() %>%   # Remove any rows with na. Because fuck 'em.
  rowwise() %>%
  mutate(avg_sentiment = mean(c(sentiment_title, sentiment_reveiw)))
# shreks.sentiment.r_title <- analyzeSentiment(shreks$r_title, # Analyse sentiment on title
#                                              removeStopwords = FALSE) # Do not remove stopwords, as titles can be short, which leads to na values.
# shreks.sentiment.review <- analyzeSentiment(shreks$review,
#                                             removeStopwords = TRUE) # Revmove stopswords.

Shreksiments <- shreks %>% # sentiment of title vs review
  select(title, sentiment_title, sentiment_reveiw) %>% 
  rename("x" = sentiment_title,
         "y" = sentiment_reveiw,
         "class" = title)
ggplot(Shreksiments, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Shrek sentiment on title and review") +
  theme_light()

Shrek_stars_title_sen <- shreks %>% # stars vs sentiment title
  select(title, stars, sentiment_title) %>% 
  rename("x" = stars,
         "y" = sentiment_title,
         "class" = title)
ggplot(Shrek_stars_title_sen, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Shrek stars and title sentiment") +
  theme_light()

Shrek_stars_review_sen <- shreks %>% # stars vs sentiment review
  select(title, stars, sentiment_reveiw) %>% 
  rename("x" = stars,
         "y" = sentiment_reveiw,
         "class" = title)
ggplot(Shrek_stars_review_sen, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Shrek stars and review sentiment") +
  theme_light()

Shrek_stars_avg_sen <- shreks %>% # stars vs sentiment review
  select(title, stars, avg_sentiment) %>% 
  rename("x" = stars,
         "y" = avg_sentiment,
         "class" = title)
ggplot(Shrek_stars_avg_sen, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Shrek stars and title and review average sentiment") +
  theme_light()

Shrek_stars_complete_sen <- shreks %>% # stars vs sentiment review
  select(title, stars, sentiment_reveiw) %>% 
  rename("x" = stars,
         "y" = sentiment_reveiw,
         "class" = title)
ggplot(Shrek_stars_complete_sen, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Shrek stars and complete sentiment") +
  theme_light()


```

### 5.1 Data initiation
<!-- XX TODO: Initiate more intersting data -->


### 5.2 Methods  


### 5.3 Algorithms and implementation  
<!-- XX TODO: explain witch algorithms and implementations that were used -->

  
### 5.4 Analysis
<!-- XX TODO: perform analysis -->


### 5.5 Results
<!-- XX TODO: Explain what we found / sum up results -->


### 6 Clustering results
<!-- XX Answer: What can you learn about that [new] data by using clustering? -->


```{r name1, warning=FALSE, echo=FALSE}

```

