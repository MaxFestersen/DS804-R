---
title: 'DS804: Exercise 11: Group Project 1: Clustering'
author: Alexander Dernild, Christian R. Andersen, Johannes Sørensen, Mathias P.
  Larsen & Max F. Hansen
date: "28/4/2021"
output: pdf_document
---
```{r echo = FALSE}
# Imports ---------------------------------------
library(tidyverse) # For convenience, plots, tables and probably some other stuff.
```

# **DS804 Assignment 1**  
## Created by  
* Alexander Ibsen Dernild, alder17  
* Christian Rohde Andersen, chran20  
* Johannes Christian Sørensen, josoe20  
* Mathias Profft Larsen, matla20  
* Max Festersen Hansen, maxfh20  

## 1. Introduction


### 1.1 The Compound dataset
For this exercise, we needed shape data set. We choose to use the compound
dataset, from C.T. Zahn, **IEEE Transactions on Computers**, 1971.
The compound data was chosen for... reasons.<!-- XX TODO: expand reason.  -->

```{r loading-dataset echo = FALSE}
# Data load
compound.df <- read.csv("Compound.txt", sep = "\t", header = F)
# Adding lables
names(compound.df) <- c("x", "y", "class")

compound.df$class <- factor(compound.df$class)
```

```{r plotting-initial-data}
ggplot(compound.df, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Compound Data") +
  theme_light()
```
Above the data can be seen, colored by class. The clases is named 1-8.
The data had 8 classes, thus 8 colors are used.


```{r normalizing-data}
norm.compound <- scale(compound.df[1:2]) %>% 
  data.frame()
norm.compound$class <- compound.df$class
td <- norm.compound[1:2] # Test data - the data we test on

ggplot(norm.compound, aes(x, y, shape = class, color = class)) +
  geom_point() +
  labs(title = "Compound Data normalized") +
  theme_light()
```
We normalize the data, to be closer to zero (centered zero). This is done to normalize the weight,
and remove bias from large numbers.

## 2 Methods  


### 2.1 Algorithms and implementation  
<!-- XX TODO: explain witch algorithms and implementations that were used -->



## 3 Analysis of the Methods
<!-- XX TODO: find analysis methods -->


### 3.1 k-means
<!-- XX TODO: perform analysis -->
````{r echo = FALSE "k-means-testing-methods"}
c_lloyd <- kmeans(td, 6, algorithm = "Lloyd")
c_macqueen <- kmeans(td, 6, algorithm = "MacQueen")
c_forgy <- kmeans(td, 6, algorithm = "Forgy")
c_har_won <- kmeans(td, 6)

test <- data.frame(lloyd = c_lloyd$cluster,
                   macqueen = c_macqueen$cluster,
                   forgy = c_forgy$cluster,
                   har_won = c_har_won$cluster,
                   class = norm.compound$class)

lloyd <- table(test$lloyd, test$class, dnn = c("Lloyd", "Class"))
macqueen <- table(test$macqueen, test$class, dnn = c("MacQueen", "Class"))
forgy <- table(test$forgy, test$class, dnn = c("Forgy", "Class"))
har_won <- table(test$har_won, test$class, dnn = c("Harting-Wong", "Class"))

lloyd
macqueen
forgy
har_won
````


### 3.2 knn
<!-- XX TODO: perform analysis -->


### 3.3 OPTICS
<!-- XX TODO: perform analysis -->


### 3.4 DBSCAN
<!-- XX TODO: perform analysis -->



## 4 Results
<!-- XX TODO: Explain what we found / sum up results -->

### 4.1 Comparison



## 5 More intresing data
<!-- XX TODO: find more intresting data for us and analyze it. -->


### 5.1 Data initiation
<!-- XX TODO: Initiate more intersting data -->


### 5.2 Methods  


### 5.3 Algorithms and implementation  
<!-- XX TODO: explain witch algorithms and implementations that were used -->

  
### 5.4 Analysis
<!-- XX TODO: perform analysis -->


### 5.5 Results
<!-- XX TODO: Explain what we found / sum up results -->


### 6 Clustering results
<!-- XX Answer: What can you learn about that [new] data by using clustering? -->


```{r echo = TRUE}

```

```{r echo = FALSE}

```
